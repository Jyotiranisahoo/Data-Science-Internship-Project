{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPEkjjwrPi/W41bu8r/bx4+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Jyotiranisahoo/Data-Science-Internship-Project/blob/main/Project_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ybwE30THaWId"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"https://raw.githubusercontent.com/Premalatha-success/Datasets/main/h1n1_vaccine_prediction.csv\")"
      ],
      "metadata": {
        "id": "THyWZKpj8E13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "Z-nPDBq08WAk",
        "outputId": "eba05eba-44c2-4b6c-d5fe-abf5988ea663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   unique_id  h1n1_worry  h1n1_awareness  antiviral_medication  \\\n",
              "0          0         1.0             0.0                   0.0   \n",
              "1          1         3.0             2.0                   0.0   \n",
              "2          2         1.0             1.0                   0.0   \n",
              "3          3         1.0             1.0                   0.0   \n",
              "4          4         2.0             1.0                   0.0   \n",
              "\n",
              "   contact_avoidance  bought_face_mask  wash_hands_frequently  \\\n",
              "0                0.0               0.0                    0.0   \n",
              "1                1.0               0.0                    1.0   \n",
              "2                1.0               0.0                    0.0   \n",
              "3                1.0               0.0                    1.0   \n",
              "4                1.0               0.0                    1.0   \n",
              "\n",
              "   avoid_large_gatherings  reduced_outside_home_cont  avoid_touch_face  ...  \\\n",
              "0                     0.0                        1.0               1.0  ...   \n",
              "1                     0.0                        1.0               1.0  ...   \n",
              "2                     0.0                        0.0               0.0  ...   \n",
              "3                     1.0                        0.0               0.0  ...   \n",
              "4                     1.0                        0.0               1.0  ...   \n",
              "\n",
              "    race     sex               income_level  marital_status  housing_status  \\\n",
              "0  White  Female              Below Poverty     Not Married             Own   \n",
              "1  White    Male              Below Poverty     Not Married            Rent   \n",
              "2  White    Male  <= $75,000, Above Poverty     Not Married             Own   \n",
              "3  White  Female              Below Poverty     Not Married            Rent   \n",
              "4  White  Female  <= $75,000, Above Poverty         Married             Own   \n",
              "\n",
              "           employment                census_msa  no_of_adults  no_of_children  \\\n",
              "0  Not in Labor Force                   Non-MSA           0.0             0.0   \n",
              "1            Employed  MSA, Not Principle  City           0.0             0.0   \n",
              "2            Employed  MSA, Not Principle  City           2.0             0.0   \n",
              "3  Not in Labor Force       MSA, Principle City           0.0             0.0   \n",
              "4            Employed  MSA, Not Principle  City           1.0             0.0   \n",
              "\n",
              "   h1n1_vaccine  \n",
              "0             0  \n",
              "1             0  \n",
              "2             0  \n",
              "3             0  \n",
              "4             0  \n",
              "\n",
              "[5 rows x 34 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-abd5b7f5-a926-48ee-bf78-2617701f89a4\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>unique_id</th>\n",
              "      <th>h1n1_worry</th>\n",
              "      <th>h1n1_awareness</th>\n",
              "      <th>antiviral_medication</th>\n",
              "      <th>contact_avoidance</th>\n",
              "      <th>bought_face_mask</th>\n",
              "      <th>wash_hands_frequently</th>\n",
              "      <th>avoid_large_gatherings</th>\n",
              "      <th>reduced_outside_home_cont</th>\n",
              "      <th>avoid_touch_face</th>\n",
              "      <th>...</th>\n",
              "      <th>race</th>\n",
              "      <th>sex</th>\n",
              "      <th>income_level</th>\n",
              "      <th>marital_status</th>\n",
              "      <th>housing_status</th>\n",
              "      <th>employment</th>\n",
              "      <th>census_msa</th>\n",
              "      <th>no_of_adults</th>\n",
              "      <th>no_of_children</th>\n",
              "      <th>h1n1_vaccine</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>Below Poverty</td>\n",
              "      <td>Not Married</td>\n",
              "      <td>Own</td>\n",
              "      <td>Not in Labor Force</td>\n",
              "      <td>Non-MSA</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>Below Poverty</td>\n",
              "      <td>Not Married</td>\n",
              "      <td>Rent</td>\n",
              "      <td>Employed</td>\n",
              "      <td>MSA, Not Principle  City</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>White</td>\n",
              "      <td>Male</td>\n",
              "      <td>&lt;= $75,000, Above Poverty</td>\n",
              "      <td>Not Married</td>\n",
              "      <td>Own</td>\n",
              "      <td>Employed</td>\n",
              "      <td>MSA, Not Principle  City</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>Below Poverty</td>\n",
              "      <td>Not Married</td>\n",
              "      <td>Rent</td>\n",
              "      <td>Not in Labor Force</td>\n",
              "      <td>MSA, Principle City</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>...</td>\n",
              "      <td>White</td>\n",
              "      <td>Female</td>\n",
              "      <td>&lt;= $75,000, Above Poverty</td>\n",
              "      <td>Married</td>\n",
              "      <td>Own</td>\n",
              "      <td>Employed</td>\n",
              "      <td>MSA, Not Principle  City</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 34 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-abd5b7f5-a926-48ee-bf78-2617701f89a4')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-abd5b7f5-a926-48ee-bf78-2617701f89a4 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-abd5b7f5-a926-48ee-bf78-2617701f89a4');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### problem statement https://www.kaggle.com/competitions/prediction-of-h1n1-vaccination/data"
      ],
      "metadata": {
        "id": "pb1vljpR8e17"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "path=('/kaggle/input/prediction-of-h1n1-vaccination/')\n",
        "train = pd.read_csv(path +'train.csv')\n",
        "train_labels = pd.read_csv(path +'train_labels.csv')\n",
        "test = pd.read_csv(path +'test.csv')\n",
        "submission = pd.read_csv(path + 'submission.csv')"
      ],
      "metadata": {
        "id": "r9oZGv-FEu2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#The light gbm model is capable of producing a warning message, but it still work\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ],
      "metadata": {
        "id": "QFvSllrvFK9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'train size :\\t\\t{train.shape}')\n",
        "print(f'train_labels size :\\t{train_labels.shape}')\n",
        "print(f'test size :\\t\\t{test.shape}')\n",
        "print(f'submission size :\\t{submission.shape}')"
      ],
      "metadata": {
        "id": "Vh6UP5kmFLMB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# The \"train_labels\" contain our target variable: \"vacc_h1n1_f\"\n",
        "train_labels"
      ],
      "metadata": {
        "id": "lEQzNULmFLUw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "sKT0nn3JF2eh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# We can observe a target value ratio of 3:1.\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "def write_percent(ax, total_size):\n",
        "    for patch in ax.patches:\n",
        "        height = patch.get_height()\n",
        "        width = patch.get_width()\n",
        "        left_coord = patch.get_x()\n",
        "        percent = height / total_size*100\n",
        "        \n",
        "        ax.text(x=left_coord + width/2,\n",
        "                y = height + total_size * 0.001,\n",
        "                s = f'{percent:1.1f}%',\n",
        "                ha = 'center')\n",
        "        \n",
        "plt.figure(figsize = (7, 6))\n",
        "ax = sns.countplot(x='vacc_h1n1_f', data = train_labels, palette='Set3')\n",
        "ax.set_title('Distribution of Target Variable')\n",
        "write_percent(ax, len(train_labels))\n"
      ],
      "metadata": {
        "id": "6UipUOhQF93U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge train data, test data\n",
        "data = pd.concat([train, test], ignore_index = True)\n",
        "print(f'train size :\\t{train.shape}')\n",
        "print(f'test size :\\t{test.shape}')\n",
        "print(f'merged size :\\t{data.shape}')"
      ],
      "metadata": {
        "id": "JGSwZf3fGEoT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a table that displays both the unique data and the missing values in a dataset.\n",
        "def resumetable(df):\n",
        "    print(f'dataset shape: {df.shape}')\n",
        "    summary = pd.DataFrame(df.dtypes, columns=['data type'])\n",
        "    summary = summary.rename(columns = {'index' : 'feature'})\n",
        "    summary['number of missing value'] = df.isnull().sum().values\n",
        "    summary['number of unique data'] = df.nunique().values\n",
        "    summary['first value'] = df.iloc[0,:]\n",
        "    summary['second value'] = df.iloc[1,:]\n",
        "    summary['third value'] = df.iloc[2,:]\n",
        "    \n",
        "    return summary\n",
        "\n",
        "resumetable(data)\n",
        "dataset shape: (70258, 38)"
      ],
      "metadata": {
        "id": "NWcaEkYgGIRC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# there are a lot of missing values, but I won't handle it this time.\n",
        "missing = pd.DataFrame(data.isna().mean().multiply(100).round(2), columns=['percent'])\n",
        "missing"
      ],
      "metadata": {
        "id": "aOVDpApeGMOs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.gridspec as gridspec\n",
        "\n",
        "def plot_target_ratio_by_features(df, features, num_rows, num_cols, size=(12,18)):\n",
        "    mpl.rc('font', size=9)\n",
        "    plt.figure(figsize = size)\n",
        "    grid = gridspec.GridSpec(num_rows, num_cols)\n",
        "    plt.subplots_adjust(wspace = 0.5, hspace = 0.5)\n",
        "    \n",
        "    for idx, feature in enumerate(features):\n",
        "        ax = plt.subplot(grid[idx])\n",
        "        sns.barplot(x=feature, y=train_labels['vacc_h1n1_f'], data = df, palette = 'Set3', ax= ax)"
      ],
      "metadata": {
        "id": "6uL1iep0GRu8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Categorize data types\n",
        "ordinal_vars = ['h1n1_concern', 'h1n1_knowledge', 'opinion_h1n1_vacc_effective', 'opinion_h1n1_risk',\n",
        "                'opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective', 'opinion_seas_risk',\n",
        "                'opinion_seas_sick_from_vacc', 'agegrp', 'education_comp', 'inc_pov']\n",
        "\n",
        "binary_vars = ['behavioral_antiviral_meds', 'behavioral_avoidance', 'behavioral_face_mask',\n",
        "               'behavioral_wash_hands', 'behavioral_large_gatherings', 'behavioral_outside_home',\n",
        "               'behavioral_touch_face', 'doctor_recc_h1n1', 'doctor_recc_seasonal', 'chronic_med_condition',\n",
        "               'child_under_6_months', 'health_insurance', 'health_worker', 'sex_i', 'marital', 'rent_own_r',\n",
        "               'census_msa']\n",
        "\n",
        "categorical_vars = ['raceeth4_i', 'employment_status', 'census_region', 'employment_industry',\n",
        "                    'employment_occupation', 'hhs_region', 'state']\n",
        "\n",
        "numerical_vars = ['n_adult_r', 'household_children', 'n_people_r']"
      ],
      "metadata": {
        "id": "Vp9VWpjwGVv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_target_ratio_by_features(data, ordinal_vars, 4, 3)\n",
        "# We will delete below feature due to issues with the confidence intervals.\n",
        "# opinion_h1n1_sick_from_vacc\n",
        "# opinion_seas_vacc_effective\n",
        "# opinion_seas_sick_from_vacc"
      ],
      "metadata": {
        "id": "ifMl_GlhGZME"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " plot_target_ratio_by_features(data, binary_vars, 6, 3)\n",
        "# We will delete below feature because there were issues with the similarity ratio of the target\n",
        "# sex_i \n",
        "\n",
        "# not binary data\n",
        "# rent_own_r \n",
        "# census_msa binary"
      ],
      "metadata": {
        "id": "0LzgMMqTGc33"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_target_ratio_by_features(data, categorical_vars, 3, 3)\n",
        "# We will delete below feature due to issues with the confidence intervals.\n",
        "# employment_industry "
      ],
      "metadata": {
        "id": "Cl33XSWhGizm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_target_ratio_by_features(data, numerical_vars, 3, 3)"
      ],
      "metadata": {
        "id": "daw0MCViGmcO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge data \n",
        "data_ordinal = data.loc[:,ordinal_vars].copy()\n",
        "data_binary = data.loc[:,binary_vars].copy()\n",
        "data_categorical = data.loc[:,categorical_vars].copy()\n",
        "data_numerical = data.loc[:,numerical_vars].copy()\n",
        "data_sorted = pd.concat([data_ordinal, data_binary, data_categorical, data_numerical], axis=1)\n",
        "resumetable(data_sorted)"
      ],
      "metadata": {
        "id": "VZuVfm0XGqaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "remove_list = ['opinion_h1n1_sick_from_vacc', 'opinion_seas_vacc_effective', 'opinion_seas_sick_from_vacc',\n",
        "               'rent_own_r', 'census_msa', 'sex_i', 'employment_industry']\n",
        "\n",
        "data = data_sorted.drop(remove_list, axis = 1)\n",
        "resumetable(data)"
      ],
      "metadata": {
        "id": "lGkPfKWJGwAZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ordinal data - ordinal encoding\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "ordinal_list = data.columns[0:8].tolist()\n",
        "ordianl_encoder = OrdinalEncoder()\n",
        "\n",
        "ordinal_data_encoded = ordianl_encoder.fit_transform(data[ordinal_list])\n",
        "ordinal_data_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "HaF4sBtJG14R",
        "outputId": "3ec7c4be-dbab-48cf-fc49-24a2faf63519"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-47861c966613>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mordinal_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mordianl_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# binary data - minmax encoding\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "binary_list = data.columns[8:22].tolist()\n",
        "binary_encoder = MinMaxScaler()\n",
        "\n",
        "binary_data_encoded = binary_encoder.fit_transform(data[binary_list])\n",
        "binary_data_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "ZVR2HQoRG646",
        "outputId": "489d01e3-b6bc-47b2-d5a3-aad0a4a96a09"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-10a2c98f728f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mbinary_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mbinary_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMinMaxScaler\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# categorical data - onehot encoding\n",
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "categoty_list = data.columns[22:28].tolist()\n",
        "onehot_encoder = OneHotEncoder()\n",
        "\n",
        "categorical_data_encoded = onehot_encoder.fit_transform(data[categoty_list])\n",
        "categorical_data_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "vhLF8-HIHFy7",
        "outputId": "0c52654e-6fea-4c7a-a378-0017a1287a70"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-b6d7283619be>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mcategoty_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0monehot_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOneHotEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# numerical data - ordinal encoding\n",
        "from sklearn.preprocessing import OrdinalEncoder\n",
        "\n",
        "numerical_list = data.columns[28:].tolist()\n",
        "ordianl_encoder = OrdinalEncoder()\n",
        "\n",
        "numerical_data_encoded = ordianl_encoder.fit_transform(data[numerical_list])\n",
        "numerical_data_encoded"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "yq-UkrULHKJs",
        "outputId": "dd4f3a6d-4179-44ab-adb9-d568ffe92a1b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-918c56d1f6ee>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnumerical_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mordianl_encoder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOrdinalEncoder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# To improve memory efficiency, it is recommended to create a sparse matrix\n",
        "from scipy import sparse\n",
        "all_data_sparse = sparse.hstack([sparse.csr_matrix(ordinal_data_encoded),\n",
        "                                 sparse.csr_matrix(binary_data_encoded),\n",
        "                                categorical_data_encoded,\n",
        "                                sparse.csr_matrix(numerical_data_encoded)],\n",
        "                               format='csr')\n",
        "all_data_sparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "bQzkntZeHOuV",
        "outputId": "a8fccafb-4d52-493a-e602-7871869d25ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-d2c27e0204c4>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# To improve memory efficiency, it is recommended to create a sparse matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msparse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m all_data_sparse = sparse.hstack([sparse.csr_matrix(ordinal_data_encoded),\n\u001b[0m\u001b[1;32m      4\u001b[0m                                  \u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbinary_data_encoded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                                 \u001b[0mcategorical_data_encoded\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'ordinal_data_encoded' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# split train, test data\n",
        "num_train = len(train)\n",
        "\n",
        "X = all_data_sparse[:num_train]\n",
        "X_test = all_data_sparse[num_train:]\n",
        "\n",
        "y = train_labels['vacc_h1n1_f'].values\n",
        "\n",
        "print(f'X size :{X.shape}')\n",
        "print(f'X_test size :{X_test.shape}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "_5lkW5iNHTg9",
        "outputId": "053e20be-0231-491d-a6b9-4d7afd1c3e56"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-3e1a4c53dcbc>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# split train, test data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mnum_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mall_data_sparse\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnum_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "import lightgbm as lgb\n",
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n",
        "                                                     test_size = 0.1,\n",
        "                                                     random_state = 97)\n",
        "\n",
        "bayes_dtrain = lgb.Dataset(X_train, y_train)\n",
        "bayes_dvalid = lgb.Dataset(X_valid, y_valid)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "nWtJdBpUHZM-",
        "outputId": "d7ecadf6-44c2-4ee2-9bb9-d7a90521043f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-2a4832c8b8e6>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlightgbm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mlgb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m X_train, X_valid, y_train, y_valid = train_test_split(X, y,\n\u001b[0m\u001b[1;32m      5\u001b[0m                                                      \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m                                                      random_state = 97)\n",
            "\u001b[0;31mNameError\u001b[0m: name 'X' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# basian optimization hyper parameter bounds\n",
        "param_bounds = {'num_leaves': (38, 42),\n",
        "                'lambda_l1': (0.68, 0.72),\n",
        "                'lambda_l2': (0.93, 1),\n",
        "                'feature_fraction': (0.65, 0.73),\n",
        "                'bagging_fraction': (0.68, 0.72),\n",
        "                'min_child_samples': (9, 11),\n",
        "                'min_child_weight': (25, 35)}\n",
        "\n",
        "fixed_params = {'objective': 'binary',\n",
        "                'learning_rate': 0.1,\n",
        "                'bagging_freq': 1,\n",
        "                'force_row_wise': True,\n",
        "                'random_state': 97}"
      ],
      "metadata": {
        "id": "dJGQqfkkHd2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def f1_score_eval(y_pred, dtrain):\n",
        "    y_true = dtrain.get_label()\n",
        "    y_pred = np.round(y_pred)\n",
        "    return 'f1_score', f1_score(y_true, y_pred), True\n",
        "\n",
        "def eval_function(num_leaves, lambda_l1, lambda_l2, feature_fraction,\n",
        "                  bagging_fraction, min_child_samples, min_child_weight):\n",
        "    \n",
        "    params = {'num_leaves': int(round(num_leaves)),\n",
        "              'lambda_l1': lambda_l1,\n",
        "              'lambda_l2': lambda_l2,\n",
        "              'feature_fraction': feature_fraction,\n",
        "              'bagging_fraction': bagging_fraction,\n",
        "              'min_child_samples': int(round(min_child_samples)),\n",
        "              'min_child_weight': min_child_weight,\n",
        "              'feature_pre_filter': False}\n",
        "    # add fixed hyperparameters\n",
        "    params. update(fixed_params)\n",
        "    \n",
        "    print('Hyperparameters:', params)\n",
        "    \n",
        "    # Train the LightGBM model\n",
        "    lgb_model = lgb.train(params=params,\n",
        "                           train_set=bayes_dtrain,\n",
        "                           num_boost_round=2500,\n",
        "                           valid_sets=bayes_dvalid,\n",
        "                           feval=f1_score_eval,\n",
        "                           early_stopping_rounds=500,\n",
        "                           verbose_eval=100)\n",
        "\n",
        "    # Make predictions with validation data\n",
        "    preds = lgb_model.predict(X_valid)\n",
        "    # Calculate the F1-score\n",
        "    f1_score_val = f1_score(y_valid, np.round(preds))\n",
        "    print(f'F1-score: {f1_score_val}\\n')\n",
        "    \n",
        "    return f1_score_val"
      ],
      "metadata": {
        "id": "Bkh5X81zHmrx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "optimizer = BayesianOptimization(f=eval_function,      \n",
        "                                 pbounds=param_bounds,\n",
        "                                 random_state=97)\n",
        "\n",
        "optimizer.maximize(init_points=5, n_iter=10)"
      ],
      "metadata": {
        "id": "4fDyfDsVHrPh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_params = optimizer.max['params']\n",
        "max_params"
      ],
      "metadata": {
        "id": "Xjxm4JnAIDN1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_params['num_leaves'] = int(round(max_params['num_leaves']))\n",
        "max_params['min_child_samples'] = int(round(max_params['min_child_samples']))"
      ],
      "metadata": {
        "id": "6zdzIxsqIGot"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "max_params"
      ],
      "metadata": {
        "id": "MeR5j6dZILv8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "folds = StratifiedKFold(n_splits=5, shuffle=True, random_state=97)\n",
        "\n",
        "# This one-dimensional array will be used as valid target values later.\n",
        "oof_val_preds = np.zeros(X.shape[0]) \n",
        "# This one-dimensional array will be used as test target values later.\n",
        "oof_test_preds = np.zeros(X_test.shape[0]) \n",
        "\n",
        "for idx, (train_idx, valid_idx) in enumerate(folds.split(X, y)):\n",
        "    print('#'*33, f'Fold {idx+1} / Fold {folds.n_splits}', '#'*33)\n",
        "    \n",
        "    X_train, y_train = X[train_idx], y[train_idx]\n",
        "    X_valid, y_valid = X[valid_idx], y[valid_idx]\n",
        "\n",
        "    # Create a Dataset for LightGBM\n",
        "    dtrain = lgb.Dataset(X_train, y_train)\n",
        "    dvalid = lgb.Dataset(X_valid, y_valid)\n",
        "                          \n",
        "    lgb_model = lgb.train(params=max_params,   \n",
        "                          train_set=dtrain,     \n",
        "                          num_boost_round=2500, \n",
        "                          valid_sets=dvalid,    \n",
        "                          feval=f1_score_eval,\n",
        "                          early_stopping_rounds=500, \n",
        "                          verbose_eval=100)\n",
        "    \n",
        "    oof_test_preds += lgb_model.predict(X_test)/folds.n_splits\n",
        "    oof_val_preds[valid_idx] += lgb_model.predict(X_valid)\n",
        "    \n",
        "    f1_score_val = f1_score(y_valid, np.round(oof_val_preds[valid_idx]))\n",
        "    print(f'F1-score: {f1_score_val}\\n')"
      ],
      "metadata": {
        "id": "2POlQ1qgIR_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print('OOF data lgb F1-score :\\t', f1_score(y, np.round(oof_val_preds)))"
      ],
      "metadata": {
        "id": "ksXAjHxvIX_n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_preds_binary = [1 if pred >= 0.5 else 0 for pred in oof_test_preds]\n",
        "\n",
        "submission['vacc_h1n1_f'] = y_preds_binary\n",
        "submission.to_csv('submission.csv', index = False)"
      ],
      "metadata": {
        "id": "7sJR8pPUIbY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submission"
      ],
      "metadata": {
        "id": "852zmhVxIeJW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}